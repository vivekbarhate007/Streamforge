version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    volumes:
      - redis-data:/data

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-streamforge}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-streamforge123}
      POSTGRES_DB: ${POSTGRES_DB:-streamforge}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
      - ./scripts/seed_postgres.sql:/docker-entrypoint-initdb.d/seed_postgres.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-streamforge}"]
      interval: 5s
      timeout: 5s
      retries: 5

  spark:
    build:
      context: ./services/spark
      dockerfile: Dockerfile
    depends_on:
      - kafka
      - postgres
    volumes:
      - ./services/spark/jobs:/app/jobs
      - ./data:/app/data
      - spark_checkpoints:/tmp/spark-checkpoints
    environment:
      KAFKA_BROKER: kafka:29092
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-streamforge}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-streamforge123}
      POSTGRES_DB: ${POSTGRES_DB:-streamforge}
    command: tail -f /dev/null

  producer:
    build:
      context: ./services/producer
      dockerfile: Dockerfile
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./services/producer:/app
    environment:
      KAFKA_BROKER: kafka:29092
      KAFKA_TOPIC: ${KAFKA_TOPIC:-user_events}
      EVENTS_PER_SECOND: ${PRODUCER_EVENTS_PER_SECOND:-10}
      TOTAL_EVENTS: ${PRODUCER_TOTAL_EVENTS:-1000}

  dbt:
    build:
      context: ./warehouse/dbt
      dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./warehouse/dbt:/dbt
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-streamforge}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-streamforge123}
      POSTGRES_DB: ${POSTGRES_DB:-streamforge}
    command: tail -f /dev/null

  api:
    build:
      context: ./services/api
      dockerfile: Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8000:8000"
    volumes:
      - ./services/api:/app
    environment:
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_USER: ${POSTGRES_USER:-streamforge}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-streamforge123}
      POSTGRES_DB: ${POSTGRES_DB:-streamforge}
      SECRET_KEY: ${API_SECRET_KEY:-your-secret-key-change-in-production}
      ALGORITHM: ${API_ALGORITHM:-HS256}
      ACCESS_TOKEN_EXPIRE_MINUTES: ${API_ACCESS_TOKEN_EXPIRE_MINUTES:-30}
      DEFAULT_ADMIN_USER: ${DEFAULT_ADMIN_USER:-admin}
      DEFAULT_ADMIN_PASSWORD: ${DEFAULT_ADMIN_PASSWORD:-admin}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  ui:
    build:
      context: ./services/ui
      dockerfile: Dockerfile
    depends_on:
      - api
    ports:
      - "3000:3000"
    volumes:
      - ./services/ui:/app
      - /app/node_modules
      - /app/.next
    environment:
      NEXT_PUBLIC_API_URL: ${NEXT_PUBLIC_API_URL:-http://localhost:8000}

volumes:
  postgres_data:
  spark_checkpoints:
  redis-data:

networks:
  default:
    name: streamforge-network

